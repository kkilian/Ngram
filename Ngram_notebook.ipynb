{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ad0622-3e8e-4d14-ae05-a25b8e4df882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from utils import get_logs, parse_logs, clean_data\n",
    "from model import NgramModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf09982b-c559-408d-b011-f7bed430bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = parse_logs(get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24e35dd8-e7f5-4fc3-992e-c00f2ec11edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keys = np.array([k for k, v in zip(logs.keys(), logs.values()) if len(v[-1]) > 1])\n",
    "white_keys = np.array([k for k, v in zip(logs.keys(), logs.values()) if len(v[-1]) > 1 and v[-1][1][0] == 'w'])\n",
    "black_keys = np.array([k for k, v in zip(logs.keys(), logs.values()) if len(v[-1]) > 1 and v[-1][1][0] == 'b'])\n",
    "remaining_keys = np.array([k for k in logs.keys() if k not in white_keys and k not in black_keys])\n",
    "draw_keys = np.array([k for k in remaining_keys if logs[k][-1] == ['d']])\n",
    "white_keys = np.append(white_keys, [k for k in remaining_keys if len(logs[k][-1]) > 1 and logs[k][-1][1][0] == 'r' and logs[k][-2][1][0] == 'w'])\n",
    "black_keys = np.append(black_keys, [k for k in remaining_keys if len(logs[k][-1]) > 1 and logs[k][-1][1][0] == 'r' and logs[k][-2][1][0] == 'b'])\n",
    "draw_keys = np.append(draw_keys, [k for k in remaining_keys if len(logs[k][-1]) > 1 and logs[k][-1][1][0] == 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e2e4daf-0f7c-48ec-8982-09c53e413a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(logs, key):\n",
    "    pieces = []\n",
    "    rows = logs[key]\n",
    "    rows_count = len(rows)\n",
    "    for i, row in enumerate(rows):\n",
    "        if len(row) == 3:\n",
    "            pieces.extend(row[1:3])\n",
    "    return pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f95eb787-48cb-4658-b942-77956ea3548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [extract_words(logs, key) for key in all_keys]\n",
    "word_test = [extract_words(logs, key) for key in all_keys][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67062bc5-00bc-490e-8cdb-c46318bf9e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_ngrams(logs, all_keys, n):\n",
    "    ngrams = [extract_ngrams(extract_words(logs, key), n) for key in all_keys]\n",
    "    concatenated_array = np.concatenate(ngrams)\n",
    "    return concatenated_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d4f4214-6426-4f86-9c01-825d54c143f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ngrams(tokens, n):\n",
    "        if n == 1:\n",
    "            tokens_extended = ['s'] + tokens    \n",
    "        else:\n",
    "            tokens_extended = ['s'] * (n - 1) + tokens \n",
    "        ngrams = []\n",
    "        for i in range(len(tokens_extended) - n):\n",
    "            if n == 1:\n",
    "                ngram = tokens_extended[i:i + n][0]\n",
    "            else:\n",
    "                ngram = tuple(tokens_extended[i:i + n])\n",
    "            ngrams.append(ngram)\n",
    "        ngrams = np.array(ngrams)\n",
    "        return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8893a47-7dcd-4254-9040-dce4ccafd31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "one = concatenate_ngrams(logs, all_keys, 1)\n",
    "two = concatenate_ngrams(logs, all_keys, 2)\n",
    "three = concatenate_ngrams(logs, all_keys, 3)\n",
    "four = concatenate_ngrams(logs, all_keys, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a975707c-e98c-432e-b8cd-52b70b494c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['s', 'wG1'],\n",
       "       ['wG1', '.'],\n",
       "       ['.', 'bG1'],\n",
       "       ['bG1', '\\\\wG1'],\n",
       "       ['\\\\wG1', 'wA1'],\n",
       "       ['wA1', 'wG1\\\\'],\n",
       "       ['wG1\\\\', 'bG2'],\n",
       "       ['bG2', '\\\\bG1'],\n",
       "       ['\\\\bG1', 'wQ'],\n",
       "       ['wQ', 'wG1-']], dtype='<U4')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef2b688-e086-403e-8ce5-52818cbc6b92",
   "metadata": {},
   "source": [
    "$$P(X_1 \\ldots X_n) = P(X_1) P(X_2|X_1) P(X_3|X_{1:2}) \\ldots P(X_n|X_{1:n-1}) = \\prod_{k=1}^{n} P(X_k|X_{1:k-1})\n",
    " $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0f1fba-b714-48cc-a89f-19498ffea1ad",
   "metadata": {},
   "source": [
    "When we use a bigram model to predict the conditional probability of the next word, we are thus making the following approximation:\n",
    "$$ P(w_n|w_{1:n-1}) \\approx P(w_n|w_{n-1})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4574af-b21f-4b97-899d-ece481e11e74",
   "metadata": {},
   "source": [
    "Then we approximate the probability of a word given its entire context as follows:\n",
    "$$ P(w_n|w_{1:n-1}) \\approx P(w_n|w_{n-N+1:n-1})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15003ae2-5a93-4d15-b96b-eb878ec8b8d1",
   "metadata": {},
   "source": [
    "We compute the count of the bigram C(wn−1wn) and normalize by the sum of all the bigrams that share the same first word wn−1. Since the sum of all bigram counts that start with a given word wn−1 must be equal to the unigram count for that word wn−1:\n",
    "$$\n",
    "P(w_n | w_{n-1}) = \\frac{{C(w_{n-1}w_n)}}{{C(w_{n-1})}}\n",
    "$$\n",
    "example :\n",
    "$$\n",
    "P('wG1' | '-bG1') = \\frac{{C('-bG1, wG1,')}}{{C('-bG1')}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c95c092d-19e6-43b8-a72f-1f827d819fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_for_key(ngram_counts, desired_key):\n",
    "    for key, value in ngram_counts.items():\n",
    "        if len(key) == len(desired_key) and all(key[i] == desired_key[i] for i in range(len(key))):\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "def calculate_probs(counted_ngrams, oneless_ngrams):\n",
    "\n",
    "    counted_ngrams_keys = [key for key in counted_ngrams.keys()]\n",
    "    oneless_ngrams_keys = [key[:-1][0] if len(key) == 2 else key[:-1] for key in counted_ngrams.keys()]\n",
    "    counted_ngrams_values = np.array([counted_ngrams[key] for key in counted_ngrams_keys])\n",
    "    oneless_ngrams_values = np.array([oneless_ngrams[key] for key in oneless_ngrams_keys])\n",
    "\n",
    "    probs = {}\n",
    "    for i in range(len(counted_ngrams_keys)):\n",
    "        key = counted_ngrams_keys[i]\n",
    "        if len(key) == 2:\n",
    "            probs[key] = counted_ngrams_values[i] / oneless_ngrams_values[i]\n",
    "        else:\n",
    "            probs[key] = counted_ngrams_values[i] / oneless_ngrams_values[i]\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1a46d65-0deb-453b-976b-117c280b015e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wG1', '.', 'bG1', 'wG1\\\\', 'wQ', '-wG1', 'bQ', '/bG1', 'wA1', '\\\\wQ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be8f6502-376a-4903-af8e-0b53f6967a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wG1',\n",
       " 'wS2-',\n",
       " 'wB1',\n",
       " 'wA1/',\n",
       " 'wA3',\n",
       " '-bQ',\n",
       " 'bS2',\n",
       " 'bA1-',\n",
       " 'bG2',\n",
       " 'bB2',\n",
       " 'bQ',\n",
       " 'wA1-',\n",
       " 'bA1',\n",
       " '-wA1',\n",
       " 'wB2']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NgramModel(2)\n",
    "model.update(two)\n",
    "model.generate_text(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d9d323-49e2-491d-ae55-ba65cdddf9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
